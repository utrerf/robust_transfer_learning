TO-DO
-----

missing cifar10:
-t cifar10 -s 201 -e {0, 3, 4} -ub {0, 1, 3} -n 25600

missing svhn:
-e 0 -t svhn -ub 0 -n -1 -s 20000000 -ne 150 -li 10 &

missing baseline (from scratch w/o transfer) for cifar10 - currently taking Madry's results

missing two e=8 points
-t {cifar10, svhn} -n -1 -ne 150 -e 8

CURRENTLY RUNNING IN AWS
------------------------

X1:		l_inf=8		baselines
	0: 	cifar100	cifar10
	1: 	mnist		svhn
	2: 	kmnist		cifar100
	3:	fmnist		mnist

X2:		ub=6; e={0,3,4,8}
	0:	cifar10
	1:	svhn
	2: 	cifar100
	3:	mnist
Berkeley:
	1:	fmnist baselines
	2: 	fmnist and kmnist (l_inf=8)
	3: 	kmnist baselines

Notes: 
	baselines: e={0,3,4}; ub={0,1,3}
	l_inf=8: ub={0,1,3} [NOT 6]

TO CONSIDER
-----------

1. training for more epochs than this:

sample_size_to_number_of_seeds_epochs_and_log_freq = {
	100  : (10, 100, 20),
	200  : (10, 100, 20),
	400  : (10, 100, 20),
	800  : (10, 100, 20),
	1600 : (10, 100, 20),
	3200 : (10,  50, 10),
	6400 : (10,  50, 10),
	12800: (5,   30,  5),
	25600: (5,   30,  5),
	-1   : (1,  150, 10),
}

2. standardizing cifar10 core results
